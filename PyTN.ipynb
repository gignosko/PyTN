{
 "metadata": {
  "name": "",
  "signature": "sha256:d60662afddfc819c995682ad7b0f719ad83eeb20da381eb235529facc2614673"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Python, a Multitool for data science."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Who's this guy talking?\n",
      "Derik Pell\n",
      "\n",
      "developer at Emma Email Marketing in Nashville\n",
      "\n",
      "budding data geek\n",
      "\n",
      "twitter: \\_gignosko_\n",
      "\n",
      "github: http://github.com/gignosko\n",
      "\n",
      "email: derik.pell@gmail.com\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#iPython Notebook\n",
      "iPython is a great substitute for the standard python interpreter. It gives a lot of additional features including tab completetion, line numbers, a host of magic functions that do things like time the execution of your code, data visualization support and a more. \n",
      "\n",
      "iPython also has this handy notebook, which is a great way to:\n",
      "* Quickly edit and run code\n",
      "* Take rich notes using markdown so you can pass them on to others\n",
      "* Insert mathematical symbols using Latex\n",
      "* Use visualize data inline\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Libraries\n",
      "The libraries we'll be using for this presentation are:\n",
      "* pandas. This is a data analytics library that gives us an easy, familiar way to wrangle our data into shape along with access to powerful data analysis and graphing capabilities by tying in to the other libraries we'll look at. \n",
      "* matplotlib. The standard for plotting in python. This library has a wide variety of built in plot types and makes it relatively easy to get your data into a plot or multiple plots. \n",
      "* numpy. A powerful library for scientific computing in python. The core of numpy revolves around it's ndarray data structure, which allows for fast calculations for a wide range of mathematical uses.\n",
      "* sklearn. Scikit Learn is a widely used Machine Learning package built on top of numpy, scipy and matplotlib. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Great for manipulating and analyzing data\n",
      "* Dataframes: 2D structure like Excel spreadsheets\n",
      "* Built on numpy ndarrays\n",
      "* Works directly with numpy and matplotlib"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loc = r'/Users/gignosko/pytn/data.json'\n",
      "single_vote_df = pd.read_json(loc)\n",
      "single_vote_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Default orientation is by column\n",
      "* First level object names become columns\n",
      "* Nested objects become rows\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(loc) as json_file:\n",
      "    json_data = json.load(json_file)  \n",
      "    yes_df = pd.DataFrame(json_data['votes']['Aye'])\n",
      "yes_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(loc) as json_file:\n",
      "    json_data = json.load(json_file)  \n",
      "    no_df = pd.DataFrame(json_data['votes']['No'])\n",
      "no_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Can do this for all 4 vote types\n",
      "* Need to pull those together: use the built-in concat()\n",
      "* Need to add a 'vote' column so we can tell which vote each row represents"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "no_df['vote'] = 'No'\n",
      "yes_df['vote'] = 'Aye'\n",
      "yes_no_df = pd.concat([no_df, yes_df])\n",
      "yes_no_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Need to buld a Dataframe for all votes in the last Congress\n",
      "* Walking through thousands of files to build up a Dataframe is time consuming.\n",
      "* pandas lets you pickle the Dataframe directly"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle_file = ('/Users/gignosko/pytn/dataframe.pkl')\n",
      "total_df = pd.read_pickle(pickle_file)\n",
      "total_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_df.index = range(1, len(total_df) +1)\n",
      "total_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Want to start drilling into the data\n",
      "* groupby() lets us, well, group by columns. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_df.columns.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_df.groupby(['party'])['vote'].count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vote_counts = total_df.groupby(['bill', 'vote_id', 'sponsor_party','party', 'vote'])['vote'].count()\n",
      "vote_counts\n",
      "#type(vote_counts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The type of a groupby is a Series\n",
      "* Series is an N x 1 array\n",
      "* The grouped by columns stack hierachically to become the indeces of the Series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vote_counts[0]\n",
      "#vote_counts.index.values[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Where are the numbes? We need numbers!\n",
      "* We'll build up a new Dataframe using loc\n",
      "* We'll add a new column to the Dataframe by using transform() to apply a function to the groupby"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_df = total_df.loc[:, ['bill', 'vote_id','party', 'vote']]\n",
      "new_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#new_df['counts'] = new_df.groupby(['vote_id','party','vote']).transform('count')\n",
      "#new_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_s1 = new_df.groupby(['vote_id','bill', 'party','vote'])['vote'].count()\n",
      "temp_s1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_df2 = temp_s1.unstack()\n",
      "temp_df2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we create a series from that Dataframe, the same as we did above, so that the vote_id, bill, party and vote all make up a  unique index with the counts as the data values. Then, we unstack the Series index, which pulls the index apart and turns each hierarchical level into a column again, but this time, it takes the counts values with it and puts them in as data. \n",
      "\n",
      "But, we have a lot of NaN values in this Dataframe and that's going to mess us up later so let's change those to 0. pandas has a function fillna() that works on both Datframes and Series to fill in the NaN values with whatever value you pass as a function parameter. For reasons I can't explain, it does not work on the Dataframe we've created, so, we'll have to get a bit creative. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* unstack() takes the index and breaks it up into columns\n",
      "* We want to get rid of the NaNs.\n",
      "* fillna() should work...but it doesn't here and I have no idea why."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this should work, but doesn't\n",
      "temp_df2.fillna(0)\n",
      "temp_df2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's do this instead."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp_df2 = temp_df2.replace(to_replace=float('nan'), value=0)\n",
      "temp_df2['Y'] = temp_df2['Aye'].add(temp_df2['Yea'])\n",
      "temp_df2['N'] = temp_df2['No'].add(temp_df2['Nay'])\n",
      "temp_df2 = temp_df2.drop(['Aye', 'Yea', 'Nay', 'No', 'Not Voting', 'Present'], axis=1)\n",
      "temp_df2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, let's start visualizing!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "temp_df2[:10].plot(kind='barh', stacked=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "temp_df2['sum'] = temp_df2.sum(axis=1)\n",
      "x = temp_df2['sum'].values \n",
      "y = np.square(x)\n",
      "\n",
      "plt.ylabel('Square of sums')\n",
      "plt.xlabel('Sum of all votes')\n",
      "plt.scatter(x=x, y=y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we've added a sum column by calling the sum() function and telling it to work across the columns. We've also imported matplotlib so we'll have better control over the plots and numpy so we can use some of it's math functions. \n",
      "\n",
      "We set the values of the sum column as the x axis and set y as a function of the square of x then added labels and made a scatter plot. And it's just that easy. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Add a sum column. sum() works across rows unless you tell it to work across columns\n",
      "* the plot can take in a list/array like in the x or a function as in the y"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import stats\n",
      "x = temp_df2['Y']\n",
      "y = temp_df2['N']\n",
      "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
      "yp = np.polyval([slope, intercept],x)\n",
      "plt.plot(x, yp)\n",
      "plt.scatter(x,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* You can plot multiple plots in one frame\n",
      "* scipy's gives us a very extensive library of stats tools\n",
      "* polyval evaluates a polynomial. *wish I'd had that in school"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Machine Learning\n",
      "* Two broad categories: supervised and unsupervised\n",
      "* We're trying to classify our data so we'll look at a classifier\n",
      "* The venerable Perceptron"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "Image(filename='perceptron.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* A naive implementation could use nested loops\n",
      "* A better implementation could involve linear algebra\n",
      "* The dot product of two matrices will multiply and then sum the inputs and the weights the way we need. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for n in range(nIterations):\n",
      "    outputs =  where(dot(inputs,weights)>0,1,0)\n",
      "    weights += eta*dot(transpose(inputs),targets-outputs)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## But why re-create the wheel when we have scikit learn?\n",
      "* Needs continuous numbers, but we have discreet characters.\n",
      "* Since we have inputs with only two classes, we're going to cheat and just use 1 and 0. \n",
      "* The Perceptron can only classify into two classes, so we can use 1 and 0 for the target data, too"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* We can drop a list of columns\n",
      "* We can also rows with particular values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drop_list = ['bill', 'display_name', 'first_name', 'id','last_name', 'state', 'vote_id']\n",
      "final_df = total_df.drop(drop_list, axis=1)\n",
      "final_df = final_df[final_df['vote'] != 'Present']\n",
      "final_df = final_df[final_df['vote'] != 'Not Voting']\n",
      "final_df = final_df[final_df['party'] != 'I']\n",
      "final_df = final_df[final_df['sponsor_party'] != 'I']\n",
      "final_df['vote'].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* We can also make a dict to remap values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "change_mapping = {'R': 0, 'D': 1, 'Nay': 0, 'No': 0, 'Yea': 1 , 'Aye': 1, 'Yes': 1}\n",
      "final_df['sponsor_party'] = final_df['sponsor_party'].map(change_mapping)\n",
      "final_df['party'] = final_df['party'].map(change_mapping)\n",
      "final_df['vote'] = final_df['vote'].map(change_mapping)\n",
      "final_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = final_df.take([2], axis=1)\n",
      "target = target.values\n",
      "target = target.astype('float64')\n",
      "target = target.ravel()\n",
      "target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = final_df.drop('vote', axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The target is the known \"answers\"\n",
      "* The Perceptron needs the target in an actual array, which is the data structure under the hood of pandas\n",
      "* The target needs to be a float64\n",
      "* ravel() flattens a N x 1 array to a 1 x N array"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* We need a set of training data and a set of testing data.\n",
      "* train_test_split will randomize our data and out target and give us a train and a test for each\n",
      "* fit() trains the Perceptron\n",
      "* predict() uses the trained machine to predict on the test data\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import perceptron\n",
      "from sklearn import cross_validation as cv\n",
      "per = perceptron.Perceptron(n_iter=10, eta0=0.002)\n",
      "data_train, data_test, target_train, target_test = cv.train_test_split(data, target)\n",
      "per.fit(data_train, target_train)\n",
      "print \"Prediction \" + str(per.predict(data_test))\n",
      "print \"Actual     \" + str(target_test)\n",
      "print \"Accuracy   \" + str(per.score(data_test, target_test)*100) + \"%\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The confusion matrix...wait. The what?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "y_pred = per.predict(data_test)\n",
      "cm = confusion_matrix(target_test, y_pred)\n",
      "print cm\n",
      "import matplotlib.pylab as plt\n",
      "plt.matshow(cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Who's this guy  tha just talked?\n",
      "Derik Pell\n",
      "\n",
      "developer at Emma Email Marketing in Nashville\n",
      "\n",
      "budding data geek\n",
      "\n",
      "twitter: \\_gignosko_\n",
      "\n",
      "github: http://github.com/gignosko\n",
      "\n",
      "email: derik.pell@gmail.com\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}